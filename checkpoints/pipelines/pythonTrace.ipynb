{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trace \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, label_binarize\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import inspect\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFlowVertex:\n",
    "    def __init__(self, parent_vertices, name, operation):\n",
    "        self.parent_vertices = parent_vertices\n",
    "        self.name = name\n",
    "        self.operation = operation\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{}, (name={}, op={})\".format(self.parent_vertices, self.name, self.operation)\n",
    "\n",
    "\n",
    "def pipeline_to_dataflow_graph(pipeline):\n",
    "    graph = []\n",
    "    layer_graph = []\n",
    "    def helper(pipeline, name_prefix=[], parent_vertices=[]):\n",
    "        if 'ColumnTransformer' in str(type(pipeline)):\n",
    "            for step in pipeline.transformers:\n",
    "                for column_name in step[2]:\n",
    "                    helper(step[1], name_prefix+[column_name], parent_vertices)\n",
    "        elif 'Pipeline' in str(type(pipeline)):\n",
    "            layer_graph.clear()\n",
    "            for i, key in enumerate(pipeline.named_steps.keys()):\n",
    "                helper(pipeline.named_steps[key], name_prefix, parent_vertices+layer_graph)\n",
    "\n",
    "        else :\n",
    "            graph.append(DataFlowVertex(parent_vertices, ''.join(name_prefix), pipeline))\n",
    "            layer_graph.append(DataFlowVertex(parent_vertices, ''.join(name_prefix), pipeline))\n",
    "\n",
    "    helper(pipeline)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from functools import wraps\n",
    "\n",
    "# class TraceCalls(object):\n",
    "#     \"\"\" Use as a decorator on functions that should be traced. Several\n",
    "#         functions can be decorated - they will all be indented according\n",
    "#         to their call depth.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, stream=sys.stdout, indent_step=2, show_ret=False):\n",
    "#         self.stream = stream\n",
    "#         self.indent_step = indent_step\n",
    "#         self.show_ret = show_ret\n",
    "\n",
    "#         # This is a class attribute since we want to share the indentation\n",
    "#         # level between different traced functions, in case they call\n",
    "#         # each other.\n",
    "#         TraceCalls.cur_indent = 0\n",
    "\n",
    "#     def __call__(self, fn):\n",
    "#         @wraps(fn)\n",
    "#         def wrapper(*args, **kwargs):\n",
    "#             indent = ' ' * TraceCalls.cur_indent\n",
    "#             argstr = ', '.join(\n",
    "#                 [repr(a) for a in args] +\n",
    "#                 [\"%s=%s\" % (a, repr(b)) for a, b in kwargs.items()])\n",
    "#             self.stream.write('%s%s(%s)\\n' % (indent, fn.__name__, argstr))\n",
    "\n",
    "#             TraceCalls.cur_indent += self.indent_step\n",
    "#             ret = fn(*args, **kwargs)\n",
    "#             TraceCalls.cur_indent -= self.indent_step\n",
    "\n",
    "#             if self.show_ret:\n",
    "#                 self.stream.write('%s--> %s\\n' % (indent, ret))\n",
    "#             return ret\n",
    "#         return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<function pd_oprations at 0x11adbd400>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @TraceCalls()\n",
    "def pd_oprations(ll):\n",
    "    a = pd.DataFrame(ll,columns = ['a'])\n",
    "    a = a.apply(lambda x: x)\n",
    "    return a\n",
    "\n",
    "pd_oprations([[1],[2],[3]])\n",
    "str(pd_oprations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_test_3(f_path = 'adult-sample.csv', a = 0):\n",
    "   \n",
    "    raw_data = pd.read_csv(f_path, na_values='?')\n",
    "    data = raw_data.dropna()\n",
    "\n",
    "    labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\n",
    "\n",
    "    feature_transformation = sklearn.compose.ColumnTransformer(transformers=[\n",
    "        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['education', 'workclass']),\n",
    "        ('numeric', StandardScaler(), ['age', 'hours-per-week'])\n",
    "    ])\n",
    "\n",
    "        \n",
    "    income_pipeline = Pipeline([\n",
    "      ('features', feature_transformation),\n",
    "      ('classifier', DecisionTreeClassifier())])\n",
    "    \n",
    "    return income_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_test_4(f_path = 'adult-sample_missing.csv', a = 0):\n",
    "    raw_data = pd.read_csv(f_path, na_values='?')\n",
    "    data = raw_data.dropna()\n",
    "\n",
    "    labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\n",
    "\n",
    "    nested_categorical_feature_transformation = Pipeline(steps=[\n",
    "        ('impute', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        ('encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    nested_feature_transformation = ColumnTransformer(transformers=[\n",
    "        ('categorical', nested_categorical_feature_transformation, ['education', 'workclass']),\n",
    "        ('numeric', StandardScaler(), ['age', 'hours-per-week'])\n",
    "    ])\n",
    "\n",
    "    nested_pipeline = Pipeline([\n",
    "      ('features', nested_feature_transformation),\n",
    "      ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "    return nested_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found module dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dis\n",
    "# saved = dis.dis(pipeline_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use module inspect to convert function codes into Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_func = inspect.getsource(pipeline_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def pipeline_test_3(f_path = 'adult-sample.csv', a = 0):\\n   \\n    raw_data = pd.read_csv(f_path, na_values='?')\\n    data = raw_data.dropna()\\n\\n    labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\\n\\n    feature_transformation = sklearn.compose.ColumnTransformer(transformers=[\\n        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['education', 'workclass']),\\n        ('numeric', StandardScaler(), ['age', 'hours-per-week'])\\n    ])\\n\\n        \\n    income_pipeline = Pipeline([\\n      ('features', feature_transformation),\\n      ('classifier', DecisionTreeClassifier())])\\n    \\n    return income_pipeline\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_func_list = [item[4:].rstrip() for item in raw_func.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"pipeline_test_3(f_path = 'adult-sample.csv', a = 0):\",\n",
       " '',\n",
       " \"raw_data = pd.read_csv(f_path, na_values='?')\",\n",
       " 'data = raw_data.dropna()',\n",
       " '',\n",
       " \"labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\",\n",
       " '',\n",
       " 'feature_transformation = sklearn.compose.ColumnTransformer(transformers=[',\n",
       " \"    ('categorical', OneHotEncoder(handle_unknown='ignore'), ['education', 'workclass']),\",\n",
       " \"    ('numeric', StandardScaler(), ['age', 'hours-per-week'])\",\n",
       " '])',\n",
       " '',\n",
       " '',\n",
       " 'income_pipeline = Pipeline([',\n",
       " \"  ('features', feature_transformation),\",\n",
       " \"  ('classifier', DecisionTreeClassifier())])\",\n",
       " '',\n",
       " 'return income_pipeline',\n",
       " '']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_func_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For_if_statement Trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bracket_balance(func_list):\n",
    "#     res = []\n",
    "#     # func_args = raw_func_list[0].split('(')[1].rstrip('):')\n",
    "#     stack_for_parent = []\n",
    "#     logs_of_parent = []\n",
    "#     for item in func_list:\n",
    "#         logs_of_parent.append(item)\n",
    "#     for char in item:\n",
    "#         if char == '(':\n",
    "#             stack_for_parent.append('(')\n",
    "#         if char == '[':\n",
    "#             stack_for_parent.append('[')\n",
    "#         if char == ')' and stack_for_parent[-1] == '(':\n",
    "#             stack_for_parent.pop(-1)\n",
    "#         if char == ']' and stack_for_parent[-1] == '[':\n",
    "#             stack_for_parent.pop(-1)\n",
    "#     if not stack_for_parent:\n",
    "#         res.append(' '.join(logs_of_parent))\n",
    "#         logs_of_parent.clear()\n",
    "#     return res\n",
    "\n",
    "# logs_of_loop_if = []\n",
    "# for item in raw_func_list:\n",
    "#     if item[-1] == ':':\n",
    "#         logs_of_loop_if.append(item)\n",
    "#     if not logs_of_loop_if and item.startwith('    '):\n",
    "#         logs_of_loop_if.append(item)\n",
    "#     else:\n",
    "#         item.strip()\n",
    "#     logs_of_parent.append(item)\n",
    "#     for char in item:\n",
    "#         if char == '(':\n",
    "#             stack_for_parent.append('(')\n",
    "#         if char == '[':\n",
    "#             stack_for_parent.append('[')\n",
    "#         if char == ')' and stack_for_parent[-1] == '(':\n",
    "#             stack_for_parent.pop(-1)\n",
    "#         if char == ']' and stack_for_parent[-1] == '[':\n",
    "#             stack_for_parent.pop(-1)\n",
    "#     if not stack_for_parent:\n",
    "#         res.append(' '.join(logs_of_parent))\n",
    "#         logs_of_parent.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Function to Convert Function to Executable Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_aggregation(func_str):\n",
    "    '''\n",
    "    This function is used for line execution with exec()\n",
    "    \n",
    "    args:\n",
    "        function strings after inspect\n",
    "    returns:\n",
    "        list of functionable strings for exec()\n",
    "    '''\n",
    "    \n",
    "    res = [] # executables for return\n",
    "    stack_for_parent = [] # stack storing brackets for line integration\n",
    "    logs_of_parent = [] # logs of lines for concat\n",
    "#     convert function codes to list of strings\n",
    "    func_list = [item.strip() for item in func_str.split('\\n')]\n",
    "#     function args\n",
    "    func_args = [item.strip() for item in func_list[0].split('(')[1].rstrip('):').split(',')]\n",
    "    for item in func_list[1:]:\n",
    "        if not item:\n",
    "            continue\n",
    "        logs_of_parent.append(item)\n",
    "        for char in item:\n",
    "            if char == '(':\n",
    "                stack_for_parent.append('(')\n",
    "            if char == '[':\n",
    "                stack_for_parent.append('[')\n",
    "            if char == ')' and stack_for_parent[-1] == '(':\n",
    "                stack_for_parent.pop(-1)\n",
    "            if char == ']' and stack_for_parent[-1] == '[':\n",
    "                stack_for_parent.pop(-1)\n",
    "        if not stack_for_parent:\n",
    "            res.append(''.join(logs_of_parent))\n",
    "            logs_of_parent.clear()\n",
    "    return func_args, res[:-1], [item.strip() for item in res[-1].replace('return ', '').split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_args, executable_list, output = func_aggregation(raw_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"f_path = 'adult-sample.csv'\", 'a = 0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"raw_data = pd.read_csv(f_path, na_values='?')\",\n",
       " 'data = raw_data.dropna()',\n",
       " \"labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\",\n",
       " \"feature_transformation = sklearn.compose.ColumnTransformer(transformers=[('categorical', OneHotEncoder(handle_unknown='ignore'), ['education', 'workclass']),('numeric', StandardScaler(), ['age', 'hours-per-week'])])\",\n",
       " \"income_pipeline = Pipeline([('features', feature_transformation),('classifier', DecisionTreeClassifier())])\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income_pipeline']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in input_args:\n",
    "    exec(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['race', 'occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_it = iter(executable_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "         race       occupation\n",
      "count     100               94\n",
      "unique      5               12\n",
      "top     White  Exec-managerial\n",
      "freq       83               15\n",
      "yes\n",
      "         race       occupation\n",
      "count      92               92\n",
      "unique      5               12\n",
      "top     White  Exec-managerial\n",
      "freq       77               15\n",
      "         race       occupation\n",
      "count      92               92\n",
      "unique      5               12\n",
      "top     White  Exec-managerial\n",
      "freq       77               15\n",
      "         race       occupation\n",
      "count      92               92\n",
      "unique      5               12\n",
      "top     White  Exec-managerial\n",
      "freq       77               15\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "for _ in range(4):\n",
    "    cur_line = next(exec_it)\n",
    "    exec(cur_line)\n",
    "    try: \n",
    "        if str(eval(f\"type({cur_line.split('=')[0].strip()})\")) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
    "            print('yes')\n",
    "            target_df = cur_line.split('=')[0].strip()\n",
    "            exec(f\"pprint.pprint({target_df}[{target_col}].describe())\")\n",
    "        else:\n",
    "            exec(f\"pprint.pprint({target_df}[{target_col}].describe())\")\n",
    "    except:\n",
    "        exec(f\"pprint.pprint({target_df}[{target_col}].describe())\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 3 debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"feature_transformation = sklearn.compose.ColumnTransformer(transformers=[('categorical', OneHotEncoder(handle_unknown='ignore'), ['education', 'workclass']),('numeric', StandardScaler(), ['age', 'hours-per-week'])])\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar = cur_line.split('=')[0].strip()\n",
    "str(eval(f\"type({tar})\"))==\"<class 'pandas.core.frame.DataFrame'>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'income_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a55e70568fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnested_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_to_dataflow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincome_pipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'income_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "nested_graph = pipeline_to_dataflow_graph(income_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nested_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5e47077418c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnested_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nested_graph' is not defined"
     ]
    }
   ],
   "source": [
    "nested_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 4 starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try add more eval metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Version\n",
    "def describe_ver(pipeline_to_test, cat_col = ['race', 'occupation', 'education'], numerical_col = ['age', 'hours-per-week']):\n",
    "    \n",
    "    def func_aggregation(func_str):\n",
    "        '''\n",
    "        This function is used for line execution with exec()\n",
    "\n",
    "        args:\n",
    "            function strings after inspect\n",
    "        returns:\n",
    "            list of functionable strings for exec()\n",
    "        '''\n",
    "\n",
    "        res = [] # executables for return\n",
    "        stack_for_parent = [] # stack storing brackets for line integration\n",
    "        logs_of_parent = [] # logs of lines for concat\n",
    "    #     convert function codes to list of strings\n",
    "        func_list = [item.strip() for item in func_str.split('\\n')]\n",
    "    #     function args\n",
    "        func_args = [item.strip() for item in func_list[0].split('(')[1].rstrip('):').split(',')]\n",
    "        for item in func_list[1:]:\n",
    "            if not item:\n",
    "                continue\n",
    "            logs_of_parent.append(item)\n",
    "            for char in item:\n",
    "                if char == '(':\n",
    "                    stack_for_parent.append('(')\n",
    "                if char == '[':\n",
    "                    stack_for_parent.append('[')\n",
    "                if char == ')' and stack_for_parent[-1] == '(':\n",
    "                    stack_for_parent.pop(-1)\n",
    "                if char == ']' and stack_for_parent[-1] == '[':\n",
    "                    stack_for_parent.pop(-1)\n",
    "            if not stack_for_parent:\n",
    "                res.append(''.join(logs_of_parent))\n",
    "                logs_of_parent.clear()\n",
    "        return func_args, res[:-1], [item.strip() for item in res[-1].replace('return ', '').split(',')]\n",
    "    \n",
    "    \n",
    "    raw_func = inspect.getsource(pipeline_to_test)\n",
    "\n",
    "\n",
    "    input_args, executable_list, outputs = func_aggregation(raw_func)\n",
    "    \n",
    "    for line in input_args:\n",
    "        exec(line)\n",
    "    \n",
    "    print()\n",
    "    print('####################### Start Pandas Opeation #######################')\n",
    "    print()\n",
    "    \n",
    "    ######################################\n",
    "    # Initialization\n",
    "    ######################################\n",
    "    prev = {}\n",
    "    \n",
    "    numerical_metric_list = ['count', 'missing_count', 'median', 'mad', 'range']\n",
    "    numerical_df = pd.DataFrame(np.inf, index = numerical_col, columns = numerical_metric_list)\n",
    "    \n",
    "    cat_metric_list = ['missing_count', 'num_class', 'class_count', 'class_percent']\n",
    "    cat_df = pd.DataFrame(np.inf, index = cat_col, columns = cat_metric_list)\n",
    "    \n",
    "    ######################################\n",
    "    # Supporting functions\n",
    "    ######################################    \n",
    "    def handle_dict(dict_1, dict_2):\n",
    "        '''\n",
    "        Calculate differences between two dictionaries\n",
    "        eg: input: d1 = {'a': 1, 'b': 2, 'c': 3, 'e': 2, 'f':4}\n",
    "                   d2 = {'a': 10, 'b': 9, 'c': 8, 'd': 7, 'e': 3}\n",
    "            output: z = {'a': -9, 'b': -7, 'c': -5, 'e': -1, 'f': 4, 'd': -7}\n",
    "        '''\n",
    "        \n",
    "        dict_1_re = {key: dict_1.get(key,0) - dict_2.get(key, 0) for key in dict_1.keys()}\n",
    "        dict_2_re = {key: dict_1.get(key,0) - dict_2.get(key, 0) for key in dict_1.keys()}\n",
    "        return {**dict_1_re, **dict_2_re}\n",
    "    \n",
    "    def get_categorical_dif(cat_df, cat_metric_list, prev):\n",
    "        '''\n",
    "        Calculate differences for categorical dataframe comparison\n",
    "        Need special handling for 'class_count' and 'class_percent' \n",
    "            since they are stored as dict in the dataframe\n",
    "        '''\n",
    "        \n",
    "        cat_dif = pd.DataFrame()\n",
    "        for i in cat_metric_list:\n",
    "            if i != 'class_count' and i != 'class_percent':\n",
    "                # if the metric is not defined as a dictionary\n",
    "                dif = cat_df[i] - prev[i]\n",
    "                cat_dif[i] = dif\n",
    "            else:\n",
    "                for idx, col in enumerate(cat_df.index):\n",
    "                    dif = handle_dict(cat_df[i][idx], prev[i][idx])\n",
    "                    cat_dif.loc[col, i] = [dif]\n",
    "        return cat_dif\n",
    "                    \n",
    "    def cal_numerical(target_df_1, numeric_feature, numerical_df):\n",
    "        '''\n",
    "        Calculate metrices for numerical features\n",
    "            including counts, missing values, Median and MAD, range/scaling\n",
    "        '''\n",
    "\n",
    "        # get counts of non NA values\n",
    "        count_log = target_df_1[numeric_feature].count()\n",
    "        numerical_df.loc[numeric_feature, 'count'] = count_log\n",
    "\n",
    "        # get missing value counts\n",
    "        missing_count_log = target_df_1[numeric_feature].isna().sum()\n",
    "        numerical_df.loc[numeric_feature, 'missing_count'] = missing_count_log\n",
    "\n",
    "        # distribution\n",
    "        # Median and MAD\n",
    "        median_log = target_df_1[numeric_feature].median()\n",
    "        numerical_df.loc[numeric_feature, 'median'] = median_log\n",
    "        if missing_count_log == 0:\n",
    "            mad_log = stats.median_absolute_deviation(target_df_1[numeric_feature])\n",
    "            numerical_df.loc[numeric_feature, 'mad'] = mad_log\n",
    "        else:\n",
    "            numerical_df.loc[numeric_feature, 'mad'] = 0\n",
    "\n",
    "        # range/ scaling\n",
    "        range_log = target_df_1[numeric_feature].max() - target_df_1[numeric_feature].min()\n",
    "        numerical_df.loc[numeric_feature, 'range'] = range_log\n",
    "\n",
    "        return numerical_df  \n",
    "    \n",
    "    def cal_categorical(target_df_1, cat_feature, cat_df):\n",
    "        '''\n",
    "        Calculate metrices for categorical features\n",
    "            including missing values, number of classes, counts for each group, percentage for each group\n",
    "        '''\n",
    "        \n",
    "        # get missing value counts\n",
    "        missing_count_log = target_df_1[cat_feature].isna().sum()\n",
    "        cat_df.loc[cat_feature, 'missing_count'] = missing_count_log\n",
    "\n",
    "        # get number of classes\n",
    "        num_class_log = len(target_df_1[cat_feature].value_counts().keys())\n",
    "        cat_df.loc[cat_feature, 'num_class'] = num_class_log\n",
    "\n",
    "        # get counts for each group\n",
    "        class_count_log = target_df_1[cat_feature].value_counts().to_dict()\n",
    "        cat_df.loc[cat_feature, 'class_count'] = [class_count_log]\n",
    "\n",
    "        # get percentage each group covers\n",
    "        class_percent_log = round(target_df_1[cat_feature].value_counts() / \\\n",
    "        target_df_1[cat_feature].value_counts().sum(), 4).to_dict()\n",
    "        cat_df.loc[cat_feature, 'class_percent'] = [class_percent_log]\n",
    "\n",
    "        return cat_df \n",
    "    \n",
    "    ######################################\n",
    "    # Execution\n",
    "    ######################################     \n",
    "    for cur_line in executable_list:\n",
    "        print_bool = False\n",
    "        exec(cur_line)\n",
    "        try: \n",
    "            if str(eval(f\"type({cur_line.split('=')[0].strip()})\")) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
    "\n",
    "                target_df = cur_line.split('=')[0].strip()\n",
    "                \n",
    "                ######################################################################################\n",
    "                # numerical features & metrices\n",
    "                # counts, missing values, Median and MAD, range/scaling\n",
    "                ######################################################################################\n",
    "                for numeric_feature in numerical_col:\n",
    "\n",
    "                    numerical_df = cal_numerical(eval(target_df), numeric_feature, numerical_df)\n",
    "\n",
    "                ######################################################################################\n",
    "                # categorical features & metrices\n",
    "                # missing values, number of classes, counts for each group, percentage for each group\n",
    "                ######################################################################################\n",
    "                for cat_feature in cat_col:\n",
    "\n",
    "                    cat_df = cal_categorical(eval(target_df), cat_feature, cat_df)\n",
    "                    \n",
    "                # KL/ Wilcox not suitable\n",
    "                # dif_2 = stats.wilcoxon(eval_mat['dist_shift_log'], prev['dist_shift_log'], zero_method='wilcox')[0]\n",
    "\n",
    "                # Use K-S test\n",
    "                # stats.ks_2samp(vector,vector1)\n",
    "\n",
    "                ######################################################################################\n",
    "                # Comparison occurs here! \n",
    "                ######################################################################################\n",
    "                if len(prev) != 0:\n",
    "                    numerical_dif = numerical_df - prev['numerical']\n",
    "                    if (numerical_dif.values != 0).any():\n",
    "                        # print(f'Metrics: {mat} changed in {col} with value {dif}')\n",
    "                        print('*'*10)\n",
    "                        print('Changes in numerical features!')\n",
    "                        print(numerical_dif)\n",
    "                        print('*'*10)\n",
    "                        print()\n",
    "                    \n",
    "                ################################## \n",
    "                # ⬆️ numerical\n",
    "                # ⬇️ categorical                \n",
    "                ##################################\n",
    "                    \n",
    "                    cat_dif = get_categorical_dif(cat_df, cat_metric_list, prev['categorical'])\n",
    "                    if (cat_dif.values != 0).any():\n",
    "                        print('*'*10)\n",
    "                        print('Changes in categorical features!')\n",
    "                        print(cat_dif)\n",
    "                        print('*'*10)\n",
    "              \n",
    "                print_bool = True\n",
    "                \n",
    "                if print_bool:\n",
    "#                     print(numerical_df)\n",
    "#                     print(cat_df)\n",
    "                    print(f'Inpected {cur_line}')\n",
    "                    print('-------------------------------------------------------')\n",
    "                    print() \n",
    "\n",
    "                # save the output for next round comparison\n",
    "                prev['numerical'] = numerical_df.copy()\n",
    "                prev['categorical'] = cat_df.copy()\n",
    "\n",
    "            elif str(eval(f\"type({cur_line.split('=')[0].strip()})\")).startswith(\"<class 'sklearn\"):\n",
    "                pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        except:\n",
    "            ######################################################################################\n",
    "            # numerical features & metrices\n",
    "            # counts, missing values, Median and MAD, range/scaling\n",
    "            ######################################################################################\n",
    "            for numeric_feature in numerical_col:\n",
    "\n",
    "                numerical_df = cal_numerical(eval(target_df), numeric_feature, numerical_df)\n",
    "\n",
    "            ######################################################################################\n",
    "            # categorical features & metrices\n",
    "            # missing values, number of classes, counts for each group, percentage for each group\n",
    "            ######################################################################################\n",
    "            for cat_feature in cat_col:\n",
    "\n",
    "                cat_df = cal_categorical(eval(target_df), cat_feature, cat_df)\n",
    "\n",
    "            ######################################################################################\n",
    "            # Comparison occurs here! \n",
    "            ######################################################################################\n",
    "            if len(prev) != 0:\n",
    "                numerical_dif = numerical_df - prev['numerical']\n",
    "                if (numerical_dif.values != 0).any():\n",
    "                    # print(f'Metrics: {mat} changed in {col} with value {dif}')\n",
    "                    print('*'*10)\n",
    "                    print('Changes in numerical features!')\n",
    "                    print(numerical_dif)\n",
    "                    print('*'*10)\n",
    "                    print()\n",
    "\n",
    "            ################################## \n",
    "            # ⬆️ numerical\n",
    "            # ⬇️ categorical                \n",
    "            ##################################\n",
    "\n",
    "                cat_dif = get_categorical_dif(cat_df, cat_metric_list, prev['categorical'])\n",
    "                if (cat_dif.values != 0).any():\n",
    "                    print('*'*10)\n",
    "                    print('Changes in categorical features!')\n",
    "                    print(cat_dif)\n",
    "                    print('*'*10)\n",
    "\n",
    "            print_bool = True\n",
    "\n",
    "            if print_bool:\n",
    "#                     print(numerical_df)\n",
    "#                     print(cat_df)\n",
    "                print(f'Inpected {cur_line}')\n",
    "                print('-------------------------------------------------------')\n",
    "                print() \n",
    "\n",
    "            # save the output for next round comparison\n",
    "            prev['numerical'] = numerical_df.copy()\n",
    "            prev['categorical'] = cat_df.copy()            \n",
    "            \n",
    "\n",
    "    nested_graph = pipeline_to_dataflow_graph(eval(f'{outputs[0]}'))\n",
    "\n",
    "    print()\n",
    "    print('####################### Start Sklearn Pipeline #######################')\n",
    "    print()\n",
    "        \n",
    "    for item in nested_graph:\n",
    "        ######################################################################################\n",
    "        # numerical features & metrices\n",
    "        # counts, missing values, Median and MAD, range/scaling\n",
    "        ######################################################################################\n",
    "        if item.name in numerical_col: \n",
    "            numeric_feature = item.name\n",
    "            \n",
    "            eval(target_df)[item.name] = item.operation.fit_transform(eval(target_df)[item.name].values.reshape(-1,1))\n",
    "            print(f\"Operations {str(item.operation).split('(')[0]} on {item.name}\")\n",
    "            \n",
    "            ##############################\n",
    "            # Metrices Calculation\n",
    "            ##############################\n",
    "            numerical_df = cal_numerical(eval(target_df), numeric_feature, numerical_df)\n",
    "            \n",
    "            ##############################\n",
    "            # Comparison\n",
    "            ##############################\n",
    "            numerical_dif = numerical_df - prev['numerical']\n",
    "            \n",
    "            if (numerical_dif.loc[numeric_feature,:].values != 0).any():\n",
    "                # print(f'Metrics: {mat} changed in {col} with value {dif}')\n",
    "                print('*'*10)\n",
    "                print('Changes in numerical features!')\n",
    "                print(numerical_dif.loc[numeric_feature,:])\n",
    "                print('*'*10)\n",
    "                print()\n",
    "                \n",
    "        ######################################################################################\n",
    "        # categorical features & metrices\n",
    "        # missing values, number of classes, counts for each group, percentage for each group\n",
    "        ######################################################################################               \n",
    "        if item.name in cat_col:\n",
    "            cat_feature = item.name\n",
    "            ##############################\n",
    "            try:\n",
    "                eval(target_df)[item.name] = item.operation.fit_transform(eval(target_df)[item.name].values.reshape(-1,1)).toarray()\n",
    "            except:\n",
    "                eval(target_df)[item.name] = item.operation.fit_transform(eval(target_df)[item.name].values.reshape(-1,1))\n",
    "            print(f\"Operations {str(item.operation).split('(')[0]} on {item.name}\")\n",
    "            \n",
    "            ##############################\n",
    "            # Metrices Calculation\n",
    "            ##############################            \n",
    "            cat_df = cal_categorical(eval(target_df), cat_feature, cat_df)\n",
    "            \n",
    "            ##############################\n",
    "            # Comparison\n",
    "            ##############################            \n",
    "            cat_dif = get_categorical_dif(cat_df, cat_metric_list, prev['categorical'])\n",
    "            if (cat_dif.loc[cat_feature,:].values != 0).any():\n",
    "                print('*'*10)\n",
    "                print('Changes in categorical features!')\n",
    "                print(cat_dif.loc[cat_feature,:])\n",
    "                print('*'*10)\n",
    "                \n",
    "        prev['numerical'] = numerical_df.copy()\n",
    "        prev['categorical'] = cat_df.copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_func = inspect.getsource(pipeline_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def pipeline_test_4(f_path = 'adult-sample_missing.csv', a = 0):\\n    raw_data = pd.read_csv(f_path, na_values='?')\\n    data = raw_data.dropna()\\n\\n    labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\\n\\n    nested_categorical_feature_transformation = Pipeline(steps=[\\n        ('impute', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\\n        ('encode', OneHotEncoder(handle_unknown='ignore'))\\n    ])\\n\\n    nested_feature_transformation = ColumnTransformer(transformers=[\\n        ('categorical', nested_categorical_feature_transformation, ['education', 'workclass']),\\n        ('numeric', StandardScaler(), ['age', 'hours-per-week'])\\n    ])\\n\\n    nested_pipeline = Pipeline([\\n      ('features', nested_feature_transformation),\\n      ('classifier', DecisionTreeClassifier())])\\n\\n    return nested_pipeline\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Start Pandas Opeation #######################\n",
      "\n",
      "Inpected raw_data = pd.read_csv(f_path, na_values='?')\n",
      "-------------------------------------------------------\n",
      "\n",
      "**********\n",
      "Changes in numerical features!\n",
      "                count  missing_count  median     mad  range\n",
      "age             -13.0           -3.0     0.0  14.826  -23.0\n",
      "hours-per-week  -16.0            0.0     0.0   0.000    0.0\n",
      "**********\n",
      "\n",
      "**********\n",
      "Changes in categorical features!\n",
      "            missing_count  num_class  \\\n",
      "race                 -4.0        0.0   \n",
      "occupation           -8.0        0.0   \n",
      "education            -2.0        0.0   \n",
      "\n",
      "                                                  class_count  \\\n",
      "race        {'White': -7, 'Black': -3, 'Amer-Indian-Eskimo...   \n",
      "occupation  {'Adm-clerical': 0, 'Craft-repair': -1, 'Exec-...   \n",
      "education   {'HS-grad': -3, 'Bachelors': -2, 'Some-college...   \n",
      "\n",
      "                                                class_percent  \n",
      "race        {'White': 0.035699999999999954, 'Black': -0.02...  \n",
      "occupation  {'Adm-clerical': 0.013499999999999984, 'Craft-...  \n",
      "education   {'HS-grad': 0.015300000000000036, 'Bachelors':...  \n",
      "**********\n",
      "Inpected data = raw_data.dropna()\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "####################### Start Sklearn Pipeline #######################\n",
      "\n",
      "Operations SimpleImputer on education\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                                                    0\n",
      "num_class                                                        0\n",
      "class_count      {'HS-grad': 0, 'Bachelors': 0, 'Some-college':...\n",
      "class_percent    {'HS-grad': 0.0, 'Bachelors': 0.0, 'Some-colle...\n",
      "Name: education, dtype: object\n",
      "**********\n",
      "Operations OneHotEncoder on education\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                             0\n",
      "num_class                               -10\n",
      "class_count               {0.0: 82, 1.0: 2}\n",
      "class_percent    {0.0: 0.9762, 1.0: 0.0238}\n",
      "Name: education, dtype: object\n",
      "**********\n",
      "Operations StandardScaler on age\n",
      "**********\n",
      "Changes in numerical features!\n",
      "count             0.000000\n",
      "missing_count     0.000000\n",
      "median          -36.101685\n",
      "mad             -13.520462\n",
      "range           -44.685191\n",
      "Name: age, dtype: float64\n",
      "**********\n",
      "\n",
      "Operations StandardScaler on hours-per-week\n",
      "**********\n",
      "Changes in numerical features!\n",
      "count             0.000000\n",
      "missing_count     0.000000\n",
      "median          -40.099129\n",
      "mad              -1.351267\n",
      "range           -63.799193\n",
      "Name: hours-per-week, dtype: float64\n",
      "**********\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/miniconda3/envs/cy1355nz/lib/python3.6/site-packages/ipykernel/__main__.py:328: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/leo/miniconda3/envs/cy1355nz/lib/python3.6/site-packages/ipykernel/__main__.py:326: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/leo/miniconda3/envs/cy1355nz/lib/python3.6/site-packages/ipykernel/__main__.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/leo/miniconda3/envs/cy1355nz/lib/python3.6/site-packages/ipykernel/__main__.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "describe_ver(pipeline_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_metric_list = ['missing_count', 'num_class', 'class_count', 'class_percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dif = pd.DataFrame()\n",
    "for i in cat_metric_list:\n",
    "    if i != 'class_count' and i != 'class_percent':\n",
    "        # if the metric is not defined as a dictionary\n",
    "        dif = prev[i] - now[i]\n",
    "        cat_dif[i] = dif\n",
    "    else:\n",
    "        for idx, col in enumerate(cat_df.index):\n",
    "            dif = handle_dict(prev[i][idx], now[i][idx])\n",
    "            cat_dif.loc[col, i] = [dif]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>num_class</th>\n",
       "      <th>class_count</th>\n",
       "      <th>class_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'White': 80, 'Black': 10, 'Amer-Indian-Eskimo...</td>\n",
       "      <td>{'White': 0.8333333333333334, 'Black': 0.10416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>{'Exec-managerial': 14, 'Adm-clerical': 13, 'C...</td>\n",
       "      <td>{'Exec-managerial': 0.15217391304347827, 'Adm-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>{'HS-grad': 30, 'Some-college': 23, 'Bachelors...</td>\n",
       "      <td>{'HS-grad': 0.30612244897959184, 'Some-college...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            missing_count  num_class  \\\n",
       "race                  4.0        5.0   \n",
       "occupation            8.0       12.0   \n",
       "education             2.0       12.0   \n",
       "\n",
       "                                                  class_count  \\\n",
       "race        {'White': 80, 'Black': 10, 'Amer-Indian-Eskimo...   \n",
       "occupation  {'Exec-managerial': 14, 'Adm-clerical': 13, 'C...   \n",
       "education   {'HS-grad': 30, 'Some-college': 23, 'Bachelors...   \n",
       "\n",
       "                                                class_percent  \n",
       "race        {'White': 0.8333333333333334, 'Black': 0.10416...  \n",
       "occupation  {'Exec-managerial': 0.15217391304347827, 'Adm-...  \n",
       "education   {'HS-grad': 0.30612244897959184, 'Some-college...  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>num_class</th>\n",
       "      <th>class_count</th>\n",
       "      <th>class_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'White': 73, 'Black': 7, 'Amer-Indian-Eskimo'...</td>\n",
       "      <td>{'White': 0.8690476190476191, 'Black': 0.08333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>{'Adm-clerical': 13, 'Craft-repair': 12, 'Exec...</td>\n",
       "      <td>{'Adm-clerical': 0.15476190476190477, 'Craft-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>{'HS-grad': 27, 'Some-college': 19, 'Bachelors...</td>\n",
       "      <td>{'HS-grad': 0.32142857142857145, 'Some-college...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            missing_count  num_class  \\\n",
       "race                  0.0        5.0   \n",
       "occupation            0.0       12.0   \n",
       "education             0.0       12.0   \n",
       "\n",
       "                                                  class_count  \\\n",
       "race        {'White': 73, 'Black': 7, 'Amer-Indian-Eskimo'...   \n",
       "occupation  {'Adm-clerical': 13, 'Craft-repair': 12, 'Exec...   \n",
       "education   {'HS-grad': 27, 'Some-college': 19, 'Bachelors...   \n",
       "\n",
       "                                                class_percent  \n",
       "race        {'White': 0.8690476190476191, 'Black': 0.08333...  \n",
       "occupation  {'Adm-clerical': 0.15476190476190477, 'Craft-r...  \n",
       "education   {'HS-grad': 0.32142857142857145, 'Some-college...  "
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>num_class</th>\n",
       "      <th>class_count</th>\n",
       "      <th>class_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'White': 7, 'Black': 3, 'Amer-Indian-Eskimo':...</td>\n",
       "      <td>{'White': -0.0357142857142857, 'Black': 0.0208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'Exec-managerial': 2, 'Adm-clerical': 0, 'Cra...</td>\n",
       "      <td>{'Exec-managerial': 0.009316770186335421, 'Adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'HS-grad': 3, 'Some-college': 4, 'Bachelors':...</td>\n",
       "      <td>{'HS-grad': -0.015306122448979609, 'Some-colle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            missing_count  num_class  \\\n",
       "race                  4.0        0.0   \n",
       "occupation            8.0        0.0   \n",
       "education             2.0        0.0   \n",
       "\n",
       "                                                  class_count  \\\n",
       "race        {'White': 7, 'Black': 3, 'Amer-Indian-Eskimo':...   \n",
       "occupation  {'Exec-managerial': 2, 'Adm-clerical': 0, 'Cra...   \n",
       "education   {'HS-grad': 3, 'Some-college': 4, 'Bachelors':...   \n",
       "\n",
       "                                                class_percent  \n",
       "race        {'White': -0.0357142857142857, 'Black': 0.0208...  \n",
       "occupation  {'Exec-managerial': 0.009316770186335421, 'Adm...  \n",
       "education   {'HS-grad': -0.015306122448979609, 'Some-colle...  "
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'White': 7,\n",
       " 'Black': 3,\n",
       " 'Amer-Indian-Eskimo': 2,\n",
       " 'Other': 0,\n",
       " 'Asian-Pac-Islander': 0}"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_dict(prev['class_count'][0], now['class_count'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_metric_list = ['missing_count', 'num_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['race', 'occupation', 'education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = pd.DataFrame(index = cat_col, columns = cat_metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'ddd':cat_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>num_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'White': 80, 'Black': 10, 'Amer-Indian-Eskim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           missing_count                                          num_class\n",
       "race                 NaN  [{'White': 80, 'Black': 10, 'Amer-Indian-Eskim...\n",
       "occupation           NaN                                                NaN\n",
       "education            NaN                                                NaN"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c['ddd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>num_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           missing_count num_class\n",
       "race                 NaN       NaN\n",
       "occupation           NaN       NaN\n",
       "education            NaN       NaN"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White                 80\n",
       "Black                 10\n",
       "Amer-Indian-Eskimo     4\n",
       "Other                  1\n",
       "Asian-Pac-Islander     1\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3: {'a': -9, 'b': -7, 'c': -5, 'e': -1, 'f': 4}\n",
      "d4: {'a': -9, 'b': -7, 'c': -5, 'd': -7, 'e': -1}\n",
      "merged: {'a': -9, 'b': -7, 'c': -5, 'e': -1, 'f': 4, 'd': -7}\n"
     ]
    }
   ],
   "source": [
    "# test dict - dict\n",
    "d1 = {'a': 1, 'b': 2, 'c': 3, 'e': 2, 'f':4}\n",
    "d2 = {'a': 10, 'b': 9, 'c': 8, 'd': 7, 'e': 3}\n",
    "d3 = {key: d1.get(key,0) - d2.get(key, 0) for key in d1.keys()}\n",
    "d4 = {key: d1.get(key,0) - d2.get(key, 0) for key in d2.keys()}\n",
    "z = {**d3, **d4}\n",
    "print('d3:', d3)\n",
    "print('d4:', d4)\n",
    "print('merged:', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('adult-sample_missing.csv')\n",
    "x1 = data_test['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['age'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     28.0\n",
       "1     58.0\n",
       "2      NaN\n",
       "3     71.0\n",
       "4     20.0\n",
       "5     46.0\n",
       "6      NaN\n",
       "7     24.0\n",
       "8     21.0\n",
       "9      NaN\n",
       "10    43.0\n",
       "11    47.0\n",
       "12    23.0\n",
       "13    38.0\n",
       "14    31.0\n",
       "15    36.0\n",
       "16    27.0\n",
       "17    32.0\n",
       "18    55.0\n",
       "19    33.0\n",
       "20    21.0\n",
       "21    25.0\n",
       "22    28.0\n",
       "23    51.0\n",
       "24    26.0\n",
       "25    62.0\n",
       "26    37.0\n",
       "27    55.0\n",
       "28    46.0\n",
       "29    47.0\n",
       "      ... \n",
       "70    48.0\n",
       "71    29.0\n",
       "72    30.0\n",
       "73    31.0\n",
       "74    40.0\n",
       "75    32.0\n",
       "76    47.0\n",
       "77    19.0\n",
       "78    45.0\n",
       "79    49.0\n",
       "80    18.0\n",
       "81    33.0\n",
       "82    48.0\n",
       "83    30.0\n",
       "84    55.0\n",
       "85    47.0\n",
       "86    72.0\n",
       "87    27.0\n",
       "88    44.0\n",
       "89    23.0\n",
       "90    33.0\n",
       "91    43.0\n",
       "92    46.0\n",
       "93    90.0\n",
       "94    34.0\n",
       "95    32.0\n",
       "96    42.0\n",
       "97    18.0\n",
       "98    25.0\n",
       "99    28.0\n",
       "Name: age, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White                 0.833333\n",
       "Black                 0.104167\n",
       "Amer-Indian-Eskimo    0.041667\n",
       "Other                 0.010417\n",
       "Asian-Pac-Islander    0.010417\n",
       "Name: race, dtype: float64"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_test['race'].value_counts() / data_test['race'].value_counts().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = x1.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.update({'wh':44})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'White': 80,\n",
       " 'Black': 10,\n",
       " 'Amer-Indian-Eskimo': 4,\n",
       " 'Other': 1,\n",
       " 'Asian-Pac-Islander': 1,\n",
       " 'wh': 44}"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'White': 80,\n",
       " 'Black': 10,\n",
       " 'Amer-Indian-Eskimo': 4,\n",
       " 'Other': 1,\n",
       " 'Asian-Pac-Islander': 1}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'White': 0,\n",
       " 'Black': 0,\n",
       " 'Amer-Indian-Eskimo': 0,\n",
       " 'Other': 0,\n",
       " 'Asian-Pac-Islander': 0,\n",
       " 'wh': 44}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_dict(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_dict(dict_1, dict_2):\n",
    "    dict_1_re = {key: dict_1.get(key,0) - dict_2.get(key, 0) for key in dict_1.keys()}\n",
    "    dict_2_re = {key: dict_1.get(key,0) - dict_2.get(key, 0) for key in dict_1.keys()}\n",
    "    return {**dict_1_re, **dict_2_re}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.loc['race','num_class'] = [x1.to_dict()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'White': 0,\n",
       " 'Black': 0,\n",
       " 'Amer-Indian-Eskimo': 0,\n",
       " 'Other': 0,\n",
       " 'Asian-Pac-Islander': 0}"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_dict(cat_df.loc['race','num_class'][0], cat_df.loc['race','num_class'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.loc['race','num_class'] = [x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>num_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[80, 10, 4, 1, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           missing_count            num_class\n",
       "race                 NaN  [[80, 10, 4, 1, 1]]\n",
       "occupation           NaN                  NaN\n",
       "education            NaN                  NaN"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'White': 80,\n",
       "  'Black': 10,\n",
       "  'Amer-Indian-Eskimo': 4,\n",
       "  'Other': 1,\n",
       "  'Asian-Pac-Islander': 1}]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df.loc['race','num_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_na = data_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
