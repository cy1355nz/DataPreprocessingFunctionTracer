{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness-Aware Instrumentation of ML-Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "from graphviz import Digraph\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, label_binarize, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def german_pipeline_easy(f_path = '../data/german_titled.csv'):\n",
    "    data = pd.read_csv(f_path)\n",
    "    # projection\n",
    "    data = data[['status_of_existing_account', 'duration_in_month', 'credit_his', 'purpose', 'credit_amt', 'saving_account', 'preset_emp', 'installment_rate', 'personal_status_and_sex', 'guarantors', 'present_residence', \n",
    "                 'property', 'age','label']]\n",
    "    # filtering\n",
    "    data = data[data.credit_amt>=4000]\n",
    "\n",
    "    #start sklearn pipeline\n",
    "    one_hot_and_impute = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "    featurizer = ColumnTransformer(transformers=[\n",
    "        ('onehot', OneHotEncoder(), ['status_of_existing_account', 'credit_his','purpose', 'saving_account', 'preset_emp']),\n",
    "        ('impute_onehot', one_hot_and_impute, ['personal_status_and_sex', 'guarantors', 'property']),\n",
    "        ('std_scaler', StandardScaler(), ['duration_in_month', 'credit_amt', 'present_residence', 'age'])\n",
    "    ])\n",
    "    pipeline = Pipeline([\n",
    "        ('features', featurizer),\n",
    "        ('learner', RandomForestClassifier())\n",
    "    ])\n",
    "    return pipeline\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def german_pipeline_normal(f_path = '../data/german_titled.csv'):\n",
    "    f_path_1 = '../data/german_titled_split_1.csv'\n",
    "    f_path_2 = '../data/german_titled_split_2.csv'\n",
    "\n",
    "    # load data\n",
    "    data_split_1 = pd.read_csv(f_path_1, index_col = 0)\n",
    "    data_split_2 = pd.read_csv(f_path_2, index_col = 0)\n",
    "\n",
    "    # join\n",
    "    data = pd.merge(data_split_1, data_split_2, on='identifier')\n",
    "\n",
    "    # drop first col\n",
    "    data.drop(data.columns[0], axis=1, inplace = True)\n",
    "\n",
    "    # projection\n",
    "    data = data[['status_of_existing_account', 'duration_in_month', 'credit_his', 'purpose', 'credit_amt', 'saving_account', 'preset_emp', 'installment_rate', 'personal_status_and_sex', 'guarantors', 'present_residence', \n",
    "                 'property', 'age','label']]\n",
    "    # filtering\n",
    "    data = data[data.credit_amt>=4000]\n",
    "\n",
    "    #start sklearn pipeline\n",
    "    one_hot_and_impute = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "    featurizer = ColumnTransformer(transformers=[\n",
    "        ('onehot', OneHotEncoder(), ['status_of_existing_account', 'credit_his','purpose', 'saving_account', 'preset_emp']),\n",
    "        ('impute_onehot', one_hot_and_impute, ['personal_status_and_sex', 'guarantors', 'property']),\n",
    "        ('std_scaler', StandardScaler(), ['duration_in_month', 'credit_amt', 'present_residence', 'age'])\n",
    "    ])\n",
    "    pipeline = Pipeline([\n",
    "        ('features', featurizer),\n",
    "        ('learner', RandomForestClassifier())\n",
    "    ])\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compass_pipeline(f1_path = '../data/compass/demographic.csv',f2_path = '../data/compass/jailrecord1.csv',f3_path = '../data/compass/jailrecord2.csv'):\n",
    "    #read csv files\n",
    "    df = pd.read_csv(f1_path)\n",
    "    df1 = pd.read_csv(f2_path)\n",
    "    df2 = pd.read_csv(f3_path)\n",
    "    \n",
    "    #drop columns inplace\n",
    "    df.drop(columns=['Unnamed: 0','age_cat'],inplace=True)\n",
    "    df1.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "    df2.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "\n",
    "    #JOIN dataframes column-wise and row-wise\n",
    "    data = pd.concat([df1,df2],ignore_index=True)\n",
    "    data = pd.merge(df, data, on=['id','name'])\n",
    "\n",
    "    #drop rows that miss a few important features\n",
    "    data = data.dropna(subset=['id', 'name','is_recid','days_b_screening_arrest','c_charge_degree','c_jail_out','c_jail_in'])\n",
    "\n",
    "    #generate a new column conditioned on existed column\n",
    "    data['age_cat'] = data.apply(lambda row:'<25' if row['age'] < 25 else '>45' if row['age']>45 else '25-45', axis=1)\n",
    "\n",
    "    #PROJECTION\n",
    "    data = data[['sex', 'dob','age','c_charge_degree', 'age_cat', 'race','score_text','priors_count','days_b_screening_arrest',\n",
    "                 'decile_score','is_recid','two_year_recid','c_jail_in','c_jail_out']]\n",
    "\n",
    "    #SELECT based on some conditions\n",
    "    data = data.loc[(data['days_b_screening_arrest'] <= 30)]\n",
    "    data = data.loc[(data['days_b_screening_arrest'] >= -30)]\n",
    "    data = data.loc[(data['is_recid'] != -1)]\n",
    "    data = data.loc[(data['c_charge_degree'] != \"O\")]\n",
    "    data = data.loc[(data['score_text'] != 'N/A')]\n",
    "    # create a new feature \n",
    "    data['c_jail_out'] = pd.to_datetime(data['c_jail_out']) \n",
    "    data['c_jail_in'] = pd.to_datetime(data['c_jail_in']) \n",
    "#     data['length_of_stay'] = data['c_jail_out'] - data['c_jail_in']\n",
    "    #specify categorical and numeric features\n",
    "    categorical = ['sex', 'c_charge_degree', 'age_cat', 'race', 'score_text', 'is_recid',\n",
    "           'two_year_recid']\n",
    "    numeric1 = ['age','priors_count', 'decile_score']\n",
    "    numeric2 = ['days_b_screening_arrest','length_of_stay']\n",
    "\n",
    "    #sklearn pipeline\n",
    "    impute1_and_onehot = Pipeline([('imputer1', SimpleImputer(strategy='most_frequent')), \n",
    "                                   ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    impute2_and_bin = Pipeline([('imputer2', SimpleImputer(strategy='mean')), \n",
    "                                ('bin_discretizer', KBinsDiscretizer(n_bins=4, encode='uniform', strategy='uniform'))])\n",
    "    featurizer = ColumnTransformer(transformers=[\n",
    "            ('impute1_and_onehot', impute1_and_onehot, categorical),\n",
    "            ('impute2_and_bin', impute2_and_bin, numeric1),\n",
    "            ('std_scaler', StandardScaler(), numeric2),\n",
    "        ])\n",
    "                               \n",
    "    pipeline = Pipeline([\n",
    "        ('features', featurizer),\n",
    "        ('learner', LogisticRegression())\n",
    "    ])\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_pipeline_easy(f_path = '../pipelines/adult-sample.csv'):\n",
    "   \n",
    "    raw_data = pd.read_csv(f_path, na_values='?')\n",
    "    data = raw_data.dropna()\n",
    "\n",
    "    labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\n",
    "\n",
    "    feature_transformation = ColumnTransformer(transformers=[\n",
    "        ('categorical', OneHotEncoder(handle_unknown='ignore'), ['education', 'workclass']),\n",
    "        ('numeric', StandardScaler(), ['age', 'hours-per-week'])\n",
    "    ])\n",
    "\n",
    "        \n",
    "    income_pipeline = Pipeline([\n",
    "      ('features', feature_transformation),\n",
    "      ('classifier', DecisionTreeClassifier())])\n",
    "    \n",
    "    return income_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_pipeline_normal(f_path = '../pipelines/adult-sample_missing.csv'):\n",
    "    raw_data = pd.read_csv(f_path, na_values='?')\n",
    "    data = raw_data.dropna()\n",
    "\n",
    "    labels = label_binarize(data['income-per-year'], ['>50K', '<=50K'])\n",
    "\n",
    "    nested_categorical_feature_transformation = Pipeline(steps=[\n",
    "        ('impute', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        ('encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    nested_feature_transformation = ColumnTransformer(transformers=[\n",
    "        ('categorical', nested_categorical_feature_transformation, ['education', 'workclass']),\n",
    "        ('numeric', StandardScaler(), ['age', 'hours-per-week'])\n",
    "    ])\n",
    "\n",
    "    nested_pipeline = Pipeline([\n",
    "      ('features', nested_feature_transformation),\n",
    "      ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "    return nested_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loan_pipeline(f_path = '../pipelines/loan_train.csv'):\n",
    "    data = pd.read_csv(f_path)\n",
    "\n",
    "    # Loan_ID is not needed in training or prediction\n",
    "    data = data.drop('Loan_ID', axis=1)\n",
    "\n",
    "#     data = data.drop('Loan_Status', axis=1)\n",
    "\n",
    "    numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = data.select_dtypes(include=['object']).drop(['Loan_Status'], axis=1).columns\n",
    "    # do transformer on numeric & categorical data respectively\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    # classifier\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('classifier', RandomForestClassifier())])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logs Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Version\n",
    "def describe_ver(pipeline_to_test, cat_col = ['race', 'occupation', 'education'], numerical_col = ['age', 'hours-per-week']):\n",
    "    \n",
    "    raw_func = inspect.getsource(pipeline_to_test)\n",
    "\n",
    "\n",
    "    input_args, executable_list, outputs = func_aggregation(raw_func)\n",
    "    \n",
    "    for line in input_args:\n",
    "        exec(line)\n",
    "    \n",
    "    print()\n",
    "    print('####################### Start Pandas Opeation #######################')\n",
    "    print()\n",
    "    \n",
    "    ######################################\n",
    "    # Initialization\n",
    "    ######################################\n",
    "    prev = {}\n",
    "    \n",
    "    numerical_metric_list = ['count', 'missing_count', 'median', 'mad', 'range']\n",
    "    numerical_df = pd.DataFrame(np.inf, index = numerical_col, columns = numerical_metric_list)\n",
    "    \n",
    "    cat_metric_list = ['missing_count', 'num_class', 'class_count', 'class_percent']\n",
    "    cat_df = pd.DataFrame(np.inf, index = cat_col, columns = cat_metric_list)\n",
    "\n",
    "    \n",
    "    ######################################\n",
    "    # Execution\n",
    "    ######################################     \n",
    "    for cur_line in executable_list:\n",
    "        print_bool = False\n",
    "        exec(cur_line)\n",
    "        if '#' in cur_line:\n",
    "            continue\n",
    "        try: \n",
    "            if str(eval(f\"type({cur_line.split('=')[0].strip()})\")) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
    "\n",
    "                target_df = cur_line.split('=')[0].strip()\n",
    "                \n",
    "                col_list = eval(target_df).columns.tolist()\n",
    "                numerical_col_sub = [i for i in numerical_col if i in col_list]\n",
    "                cat_col_sub = [j for j in cat_col if j in col_list]\n",
    "                \n",
    "                if len(numerical_col_sub) != 0:\n",
    "                    ######################################################################################\n",
    "                    # numerical features & metrices\n",
    "                    # counts, missing values, Median and MAD, range/scaling\n",
    "                    ######################################################################################\n",
    "                    for numeric_feature in numerical_col_sub:\n",
    "\n",
    "                        numerical_df = cal_numerical(eval(target_df), numeric_feature, numerical_df)\n",
    "                \n",
    "                if len(cat_col_sub) != 0:\n",
    "                    ######################################################################################\n",
    "                    # categorical features & metrices\n",
    "                    # missing values, number of classes, counts for each group, percentage for each group\n",
    "                    ######################################################################################\n",
    "                    for cat_feature in cat_col_sub:\n",
    "\n",
    "                        cat_df = cal_categorical(eval(target_df), cat_feature, cat_df)\n",
    "                    \n",
    "\n",
    "                ######################################################################################\n",
    "                # Comparison occurs here! \n",
    "                ######################################################################################\n",
    "                if len(prev) != 0:\n",
    "                    numerical_dif = numerical_df - prev['numerical']\n",
    "                    if (numerical_dif.values != 0).any():\n",
    "                        # print(f'Metrics: {mat} changed in {col} with value {dif}')\n",
    "                        print('*'*10)\n",
    "                        print('Changes in numerical features!')\n",
    "                        print(numerical_dif)\n",
    "                        print('*'*10)\n",
    "                        print()\n",
    "                    \n",
    "                ################################## \n",
    "                # ⬆️ numerical\n",
    "                # ⬇️ categorical                \n",
    "                ##################################\n",
    "                    \n",
    "                    cat_dif = get_categorical_dif(cat_df, cat_metric_list, prev['categorical'])\n",
    "                    if (cat_dif.values != 0).any():\n",
    "                        print('*'*10)\n",
    "                        print('Changes in categorical features!')\n",
    "                        print(cat_dif)\n",
    "                        print('*'*10)\n",
    "              \n",
    "                print_bool = True\n",
    "                \n",
    "                if print_bool:\n",
    "                    print(f'Inpected {cur_line}')\n",
    "                    print('-------------------------------------------------------')\n",
    "                    print() \n",
    "\n",
    "                # save the output for next round comparison\n",
    "                prev['numerical'] = numerical_df.copy()\n",
    "                prev['categorical'] = cat_df.copy()\n",
    "\n",
    "            elif str(eval(f\"type({cur_line.split('=')[0].strip()})\")).startswith(\"<class 'sklearn\"):\n",
    "                pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        except:\n",
    "            ######################################################################################\n",
    "            # numerical features & metrices\n",
    "            # counts, missing values, Median and MAD, range/scaling\n",
    "            ######################################################################################\n",
    "            for numeric_feature in numerical_col:\n",
    "\n",
    "                numerical_df = cal_numerical(eval(target_df), numeric_feature, numerical_df)\n",
    "\n",
    "            ######################################################################################\n",
    "            # categorical features & metrices\n",
    "            # missing values, number of classes, counts for each group, percentage for each group\n",
    "            ######################################################################################\n",
    "            for cat_feature in cat_col:\n",
    "\n",
    "                cat_df = cal_categorical(eval(target_df), cat_feature, cat_df)\n",
    "\n",
    "            ######################################################################################\n",
    "            # Comparison occurs here! \n",
    "            ######################################################################################\n",
    "            if len(prev) != 0:\n",
    "                numerical_dif = numerical_df - prev['numerical']\n",
    "                if (numerical_dif.values != 0).any():\n",
    "                    # print(f'Metrics: {mat} changed in {col} with value {dif}')\n",
    "                    print('*'*10)\n",
    "                    print('Changes in numerical features!')\n",
    "                    print(numerical_dif)\n",
    "                    print('*'*10)\n",
    "                    print()\n",
    "\n",
    "            ################################## \n",
    "            # ⬆️ numerical\n",
    "            # ⬇️ categorical                \n",
    "            ##################################\n",
    "\n",
    "                cat_dif = get_categorical_dif(cat_df, cat_metric_list, prev['categorical'])\n",
    "                if (cat_dif.values != 0).any():\n",
    "                    print('*'*10)\n",
    "                    print('Changes in categorical features!')\n",
    "                    print(cat_dif)\n",
    "                    print('*'*10)\n",
    "\n",
    "            print_bool = True\n",
    "\n",
    "            if print_bool:\n",
    "                print(f'Inpected {cur_line}')\n",
    "                print('-------------------------------------------------------')\n",
    "                print() \n",
    "\n",
    "            # save the output for next round comparison\n",
    "            prev['numerical'] = numerical_df.copy()\n",
    "            prev['categorical'] = cat_df.copy()            \n",
    "            \n",
    "\n",
    "    nested_graph = pipeline_to_dataflow_graph(eval(f'{outputs[0]}'))\n",
    "\n",
    "    print()\n",
    "    print('####################### Start Sklearn Pipeline #######################')\n",
    "    print()\n",
    "        \n",
    "    for item in nested_graph:\n",
    "        ######################################################################################\n",
    "        # numerical features & metrices\n",
    "        # counts, missing values, Median and MAD, range/scaling\n",
    "        ######################################################################################\n",
    "        if item.name in numerical_col: \n",
    "            numeric_feature = item.name\n",
    "            \n",
    "            eval(target_df)[item.name] = item.operation.fit_transform(eval(target_df)[item.name].values.reshape(-1,1))\n",
    "            print(f\"Operations {str(item.operation).split('(')[0]} on {item.name}\")\n",
    "            \n",
    "            ##############################\n",
    "            # Metrices Calculation\n",
    "            ##############################\n",
    "            numerical_df = cal_numerical(eval(target_df), numeric_feature, numerical_df)\n",
    "            \n",
    "            ##############################\n",
    "            # Comparison\n",
    "            ##############################\n",
    "            numerical_dif = numerical_df - prev['numerical']\n",
    "            \n",
    "            if (numerical_dif.loc[numeric_feature,:].values != 0).any():\n",
    "                # print(f'Metrics: {mat} changed in {col} with value {dif}')\n",
    "                print('*'*10)\n",
    "                print('Changes in numerical features!')\n",
    "                print(numerical_dif.loc[numeric_feature,:])\n",
    "                print('*'*10)\n",
    "                print()\n",
    "                \n",
    "        ######################################################################################\n",
    "        # categorical features & metrices\n",
    "        # missing values, number of classes, counts for each group, percentage for each group\n",
    "        ######################################################################################               \n",
    "        if item.name in cat_col:\n",
    "            cat_feature = item.name\n",
    "            ##############################\n",
    "            try:\n",
    "                eval(target_df)[item.name] = item.operation.fit_transform(eval(target_df)[item.name].values.reshape(-1,1)).toarray()\n",
    "            except:\n",
    "                eval(target_df)[item.name] = item.operation.fit_transform(eval(target_df)[item.name].values.reshape(-1,1))\n",
    "            print(f\"Operations {str(item.operation).split('(')[0]} on {item.name}\")\n",
    "            \n",
    "            ##############################\n",
    "            # Metrices Calculation\n",
    "            ##############################            \n",
    "            cat_df = cal_categorical(eval(target_df), cat_feature, cat_df)\n",
    "            \n",
    "            ##############################\n",
    "            # Comparison\n",
    "            ##############################            \n",
    "            cat_dif = get_categorical_dif(cat_df, cat_metric_list, prev['categorical'])\n",
    "            if (cat_dif.loc[cat_feature,:].values != 0).any():\n",
    "                print('*'*10)\n",
    "                print('Changes in categorical features!')\n",
    "                print(cat_dif.loc[cat_feature,:])\n",
    "                print('*'*10)\n",
    "                print()\n",
    "                \n",
    "        prev['numerical'] = numerical_df.copy()\n",
    "        prev['categorical'] = cat_df.copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Start Pandas Opeation #######################\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e66ed1bb4af7>\u001b[0m in \u001b[0;36mdescribe_ver\u001b[0;34m(pipeline_to_test, cat_col, numerical_col)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0mnumerical_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_numerical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/deml-project-6/fairness_detection/utils.py\u001b[0m in \u001b[0;36mcal_numerical\u001b[0;34m(target_df_1, numeric_feature, numerical_df)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# get counts of non NA values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mcount_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_df_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mnumerical_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5f8e802d582e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdescribe_ver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgerman_pipeline_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'personal_status_and_sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-e66ed1bb4af7>\u001b[0m in \u001b[0;36mdescribe_ver\u001b[0;34m(pipeline_to_test, cat_col, numerical_col)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnumeric_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumerical_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mnumerical_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_numerical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m######################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/deml-project-6/fairness_detection/utils.py\u001b[0m in \u001b[0;36mcal_numerical\u001b[0;34m(target_df_1, numeric_feature, numerical_df)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# get counts of non NA values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mcount_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_df_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mnumerical_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "describe_ver(german_pipeline_normal, ['personal_status_and_sex'], ['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAG Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pd_lines(pipeline_func):\n",
    "    pipeline_func = inspect.getsource(pipeline_func)\n",
    "    pd_lines = []\n",
    "    input_args , executable_list, _ = func_aggregation(pipeline_func)\n",
    "    for line in input_args:\n",
    "        exec(line)\n",
    "    for cur_line in executable_list:\n",
    "        exec(cur_line)\n",
    "        try: \n",
    "            if 'inplace' in cur_line:\n",
    "                pd_lines.append(cur_line)\n",
    "            elif str(eval(f\"type({cur_line.split('=')[0].strip()})\")).startswith(\"<class 'pandas\"):\n",
    "                pd_lines.append(cur_line)\n",
    "        except:\n",
    "            pass\n",
    "    return pd_lines\n",
    "\n",
    "def pd_to_dataflow_graph(pipeline_func, parent_vertices=[]):\n",
    "    executable_list = find_pd_lines(pipeline_func)\n",
    "    graph = []\n",
    "    previous = []\n",
    "    \n",
    "    for line in executable_list:\n",
    "        if 'inplace' in line and '#' not in line:\n",
    "            df_name = line.split('.')[0]\n",
    "            func_name = line.split('.')[1].split('(')[0].strip()\n",
    "            col_effect = line.split('[')[1].split(']')[0].strip()\n",
    "            if len(previous) > 1:\n",
    "                for node in previous:\n",
    "                    if node.name == df_name:\n",
    "                        vertex = DataFlowVertex([node], df_name+'_drop', func_name+' '+col_effect, col_effect)\n",
    "                        previous.append(vertex)\n",
    "                        previous.remove(node)     \n",
    "            else:\n",
    "                vertex = DataFlowVertex(previous, df_name+'_drop', func_name+' '+col_effect, col_effect)\n",
    "                previous = [vertex]\n",
    "        else:\n",
    "            var_name = line.split('=')[0].strip()\n",
    "\n",
    "            # match \".func_name(...)\"\n",
    "            pd_func = re.search('\\.\\s*([_a-z]*)\\s*\\(',line)  \n",
    "            if pd_func:\n",
    "                func_name = pd_func.group(1)\n",
    "                params = re.search('\\(([^\\)]*)\\)',line)  #\"(...)\"\n",
    "\n",
    "                if params:\n",
    "                    params = params.group(1).strip()\n",
    "\n",
    "                    if func_name == 'read_csv': #df = pd.read_csv(path)\n",
    "                        vertex = DataFlowVertex(parent_vertices,var_name, func_name, params)\n",
    "                        previous.append(vertex)\n",
    "\n",
    "                    elif func_name in ['join','merge','concat']:\n",
    "                        if func_name == 'concat': #df_new = pd.concat([df1,df2],keys=[])\n",
    "                            df_names = [name.strip() for name in params.strip('[]').split(',')]\n",
    "\n",
    "                        else: # df_new = df1.join/merge(df2,on='...',how='...')\n",
    "                            df_names = [re.split(\"[.=]\",line)[1].strip(), params.split(',')[0].strip()]      \n",
    "                        parent_vertices = search_vertex_by_names(df_names, graph) #search in graph by df_names\n",
    "                        vertex = DataFlowVertex(previous, var_name, func_name, params) #TODO vertex name?\n",
    "                        previous = [vertex]\n",
    "                    elif 'lambda' in params:\n",
    "                        cols = var_name.split('[')[1].split(']')[0].strip()\n",
    "                        vertex = DataFlowVertex(previous, func_name+' '+cols, func_name, params)\n",
    "                        previous = [vertex]\n",
    "                    elif '[' in var_name:\n",
    "                        cols = var_name.split('[')[1].split(']')[0].strip()\n",
    "                        vertex = DataFlowVertex(previous, func_name+' '+cols+' '+params, func_name, params)\n",
    "                        previous = [vertex]\n",
    "                    else:\n",
    "                        vertex = DataFlowVertex(previous, func_name+' '+params, func_name, params)\n",
    "                        previous = [vertex]\n",
    "\n",
    "\n",
    "            # filter operation: \"df[[cols]]\", \"df[condition]\",\"df.loc[]\",\"df.iloc[]\"\n",
    "            else:\n",
    "                is_filter = re.search('\\(([^\\)]*)\\)',line) #\"[...]\"\n",
    "                if is_filter:\n",
    "                    filter_cond = is_filter.group(1)\n",
    "                    vertex = DataFlowVertex(previous, 'select '+filter_cond, 'filter', filter_cond)\n",
    "                    previous = [vertex]\n",
    "\n",
    "        graph.append(vertex)\n",
    "            \n",
    "    return graph, previous\n",
    "\n",
    "\n",
    "def sklearn_to_dataflow_graph(pipeline, parent_vertices=[]):\n",
    "    \n",
    "    graph = pipeline_to_dataflow_graph_full(pipeline, name_prefix='', parent_vertices=[])\n",
    "    for node in graph:\n",
    "        if node.parent_vertices==[]:\n",
    "            node.parent_vertices = parent_vertices\n",
    "    return graph\n",
    "\n",
    "def visualize(nested_graph, save_file_path ='./pipeline.gv'):\n",
    "    dot = Digraph(comment='preprocessing_pipeline')\n",
    "\n",
    "    for node in nested_graph:\n",
    "        dot.node(node.name,label = node.name+',\\nop='+node.operation)\n",
    "        parents = node.parent_vertices \n",
    "        \n",
    "        for parent in parents:\n",
    "            dot.edge(parent.name, node.name)\n",
    "    dot.render(save_file_path, view=True)\n",
    "    return dot\n",
    "\n",
    "################# PUT EVERYTHING TOGETHER #################\n",
    "def dag_plot(func_pipe):\n",
    "    pd_graph, parent_vertices = pd_to_dataflow_graph(func_pipe)\n",
    "    pipeline = eval(func_pipe.__name__+'()')\n",
    "    sklearn_graph = sklearn_to_dataflow_graph(pipeline, parent_vertices)\n",
    "    pd_graph.extend(sklearn_graph)\n",
    "    visualize(pd_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_tracer(pipeline, cat_col, numerical_col):\n",
    "    dag_plot(pipeline)\n",
    "    describe_ver(pipeline, cat_col, numerical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Start Pandas Opeation #######################\n",
      "\n",
      "Inpected raw_data = pd.read_csv(f_path, na_values='?')\n",
      "-------------------------------------------------------\n",
      "\n",
      "**********\n",
      "Changes in numerical features!\n",
      "                count  missing_count  median     mad  range\n",
      "age              -8.0            0.0     0.0 -0.7413  -19.0\n",
      "hours-per-week   -8.0            0.0     0.0 -1.4826    0.0\n",
      "**********\n",
      "\n",
      "**********\n",
      "Changes in categorical features!\n",
      "            missing_count  num_class  \\\n",
      "race                  0.0        0.0   \n",
      "occupation           -6.0        0.0   \n",
      "education             0.0        0.0   \n",
      "\n",
      "                                                  class_count  \\\n",
      "race        {'White': -6, 'Black': -1, 'Amer-Indian-Eskimo...   \n",
      "occupation  {'Exec-managerial': 0, 'Adm-clerical': 0, 'Cra...   \n",
      "education   {'HS-grad': -1, 'Bachelors': 0, 'Some-college'...   \n",
      "\n",
      "                                                class_percent  \n",
      "race        {'White': 0.007000000000000006, 'Black': -0.00...  \n",
      "occupation  {'Exec-managerial': 0.003400000000000014, 'Adm...  \n",
      "education   {'HS-grad': 0.015199999999999991, 'Bachelors':...  \n",
      "**********\n",
      "Inpected data = raw_data.dropna()\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "####################### Start Sklearn Pipeline #######################\n",
      "\n",
      "Operations OneHotEncoder on education\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                             0\n",
      "num_class                               -10\n",
      "class_count               {0.0: 90, 1.0: 2}\n",
      "class_percent    {0.0: 0.9783, 1.0: 0.0217}\n",
      "Name: education, dtype: object\n",
      "**********\n",
      "\n",
      "Operations StandardScaler on age\n",
      "**********\n",
      "Changes in numerical features!\n",
      "count             0.000000\n",
      "missing_count     0.000000\n",
      "median          -36.105873\n",
      "mad             -12.870633\n",
      "range           -48.431530\n",
      "Name: age, dtype: float64\n",
      "**********\n",
      "\n",
      "Operations StandardScaler on hours-per-week\n",
      "**********\n",
      "Changes in numerical features!\n",
      "count             0.000000\n",
      "missing_count     0.000000\n",
      "median          -40.081371\n",
      "mad               0.000000\n",
      "range           -63.761564\n",
      "Name: hours-per-week, dtype: float64\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# adult_pipeline\n",
    "# cat_col = ['race', 'occupation', 'education'], numerical_col = ['age', 'hours-per-week']\n",
    "func_tracer(adult_pipeline_easy, cat_col = ['race', 'occupation', 'education'], numerical_col = ['age', 'hours-per-week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Start Pandas Opeation #######################\n",
      "\n",
      "Inpected data = pd.read_csv(f_path)\n",
      "-------------------------------------------------------\n",
      "\n",
      "**********\n",
      "Changes in categorical features!\n",
      "           missing_count  num_class                         class_count  \\\n",
      "Gender               0.0        0.0            {'Male': 0, 'Female': 0}   \n",
      "Education            0.0        0.0  {'Graduate': 0, 'Not Graduate': 0}   \n",
      "\n",
      "                                    class_percent  \n",
      "Gender               {'Male': 0.0, 'Female': 0.0}  \n",
      "Education  {'Graduate': 0.0, 'Not Graduate': 0.0}  \n",
      "**********\n",
      "Inpected data = data.drop('Loan_ID', axis=1)\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "####################### Start Sklearn Pipeline #######################\n",
      "\n",
      "Operations SimpleImputer on Gender\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                                                  -13\n",
      "num_class                                                        1\n",
      "class_count                {'Male': 0, 'Female': 0, 'missing': 13}\n",
      "class_percent    {'Male': -0.017199999999999993, 'Female': -0.0...\n",
      "Name: Gender, dtype: object\n",
      "**********\n",
      "\n",
      "Operations OneHotEncoder on Gender\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                             0\n",
      "num_class                                -1\n",
      "class_count            {0.0: 502, 1.0: 112}\n",
      "class_percent    {0.0: 0.8176, 1.0: 0.1824}\n",
      "Name: Gender, dtype: object\n",
      "**********\n",
      "\n",
      "Operations SimpleImputer on Education\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                                         0\n",
      "num_class                                             0\n",
      "class_count          {'Graduate': 0, 'Not Graduate': 0}\n",
      "class_percent    {'Graduate': 0.0, 'Not Graduate': 0.0}\n",
      "Name: Education, dtype: object\n",
      "**********\n",
      "\n",
      "Operations OneHotEncoder on Education\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                             0\n",
      "num_class                                 0\n",
      "class_count            {1.0: 480, 0.0: 134}\n",
      "class_percent    {1.0: 0.7818, 0.0: 0.2182}\n",
      "Name: Education, dtype: object\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loan_pipeline\n",
    "# cat_col = ['Gender', 'Education'], numerical_col = []\n",
    "func_tracer(loan_pipeline, cat_col = ['Gender', 'Education'], numerical_col = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Start Pandas Opeation #######################\n",
      "\n",
      "Inpected df = pd.read_csv(f1_path)\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'race'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e66ed1bb4af7>\u001b[0m in \u001b[0;36mdescribe_ver\u001b[0;34m(pipeline_to_test, cat_col, numerical_col)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                     \u001b[0mcat_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/deml-project-6/fairness_detection/utils.py\u001b[0m in \u001b[0;36mcal_categorical\u001b[0;34m(target_df_1, cat_feature, cat_df)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# get missing value counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mmissing_count_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_df_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mcat_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'missing_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_count_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-04b2b6382e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#compass_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# cat_col = ['race'], numerical_col = ['age']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfunc_tracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompass_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'race'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-becb023df966>\u001b[0m in \u001b[0;36mfunc_tracer\u001b[0;34m(pipeline, cat_col, numerical_col)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunc_tracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mto_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdag_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdescribe_ver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-e66ed1bb4af7>\u001b[0m in \u001b[0;36mdescribe_ver\u001b[0;34m(pipeline_to_test, cat_col, numerical_col)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcat_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mcat_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m######################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/deml-project-6/fairness_detection/utils.py\u001b[0m in \u001b[0;36mcal_categorical\u001b[0;34m(target_df_1, cat_feature, cat_df)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# get missing value counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mmissing_count_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_df_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_feature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mcat_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'missing_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing_count_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race'"
     ]
    }
   ],
   "source": [
    "#compass_pipeline\n",
    "# cat_col = ['race'], numerical_col = ['age']\n",
    "func_tracer(compass_pipeline, cat_col = ['race'], numerical_col = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################### Start Pandas Opeation #######################\n",
      "\n",
      "Inpected data = pd.read_csv(f_path)\n",
      "-------------------------------------------------------\n",
      "\n",
      "**********\n",
      "Changes in categorical features!\n",
      "                         missing_count  num_class  \\\n",
      "personal_status_and_sex            0.0        0.0   \n",
      "\n",
      "                                                      class_count  \\\n",
      "personal_status_and_sex  {'A93': 0, 'A92': 0, 'A94': 0, 'A91': 0}   \n",
      "\n",
      "                                                            class_percent  \n",
      "personal_status_and_sex  {'A93': 0.0, 'A92': 0.0, 'A94': 0.0, 'A91': 0.0}  \n",
      "**********\n",
      "Inpected data = data[['status_of_existing_account', 'duration_in_month', 'credit_his', 'purpose', 'credit_amt', 'saving_account', 'preset_emp', 'installment_rate', 'personal_status_and_sex', 'guarantors', 'present_residence','property', 'age','label']]\n",
      "-------------------------------------------------------\n",
      "\n",
      "**********\n",
      "Changes in numerical features!\n",
      "     count  missing_count  median     mad  range\n",
      "age -754.0            0.0     0.5  0.7413   -1.0\n",
      "**********\n",
      "\n",
      "**********\n",
      "Changes in categorical features!\n",
      "                         missing_count  num_class  \\\n",
      "personal_status_and_sex            0.0        0.0   \n",
      "\n",
      "                                                               class_count  \\\n",
      "personal_status_and_sex  {'A93': -384, 'A92': -251, 'A91': -37, 'A94': ...   \n",
      "\n",
      "                                                             class_percent  \n",
      "personal_status_and_sex  {'A93': 0.11869999999999992, 'A92': -0.0701999...  \n",
      "**********\n",
      "Inpected data = data[data.credit_amt>=4000]\n",
      "-------------------------------------------------------\n",
      "\n",
      "\n",
      "####################### Start Sklearn Pipeline #######################\n",
      "\n",
      "Operations SimpleImputer on personal_status_and_sex\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                                                   0\n",
      "num_class                                                       0\n",
      "class_count              {'A93': 0, 'A92': 0, 'A91': 0, 'A94': 0}\n",
      "class_percent    {'A93': 0.0, 'A92': 0.0, 'A91': 0.0, 'A94': 0.0}\n",
      "Name: personal_status_and_sex, dtype: object\n",
      "**********\n",
      "\n",
      "Operations OneHotEncoder on personal_status_and_sex\n",
      "**********\n",
      "Changes in categorical features!\n",
      "missing_count                             0\n",
      "num_class                                -2\n",
      "class_count             {0.0: 233, 1.0: 13}\n",
      "class_percent    {0.0: 0.9472, 1.0: 0.0528}\n",
      "Name: personal_status_and_sex, dtype: object\n",
      "**********\n",
      "\n",
      "Operations StandardScaler on age\n",
      "**********\n",
      "Changes in numerical features!\n",
      "count             0.000000\n",
      "missing_count     0.000000\n",
      "median          -33.734404\n",
      "mad             -10.133057\n",
      "range           -50.120790\n",
      "Name: age, dtype: float64\n",
      "**********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# german_pipeline\n",
    "# cat_col = ['personal_status_and_sex'], numerical_col = ['age']\n",
    "func_tracer(german_pipeline_easy, cat_col = ['personal_status_and_sex'], numerical_col = ['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
